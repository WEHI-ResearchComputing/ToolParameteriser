{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job(ABC):\n",
    "    \"\"\"\n",
    "    The Job interface declares the operations that all concrete jobs\n",
    "    must implement.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def readBenchmarkingProfiles(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def createRepository(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def copyInputFiles(self) -> str:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def createExecutableBatchFile(self) -> str:\n",
    "        pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Concrete Jobs provide various implementations of the Job interface.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class AbstractJob(Job):\n",
    "    def __init__(\n",
    "        self,\n",
    "        BenchmarkingCSVFile_path,\n",
    "        InputFiles_path,\n",
    "        storage_path,\n",
    "        Number_of_jobs_repetition,\n",
    "    ):\n",
    "        self.csvfile = BenchmarkingCSVFile_path\n",
    "        self.path = InputFiles_path\n",
    "        self.src = storage_path\n",
    "        self.dest = Number_of_jobs_repetition\n",
    "\n",
    "    def readBenchmarkingProfiles(self) -> list:\n",
    "        job_parameters = []\n",
    "\n",
    "        with open(self.csvfile, \"r\") as file:\n",
    "            csv_file = csv.DictReader(file)\n",
    "            for row in csv_file:\n",
    "                job_parameters.append(dict(row))\n",
    "\n",
    "        return job_parameters\n",
    "\n",
    "    def createRepository(self) -> None:\n",
    "        os.makedirs(self.path)\n",
    "\n",
    "    def copyInputFiles(self) -> None:\n",
    "        try:\n",
    "            shutil.copytree(self.src, self.dest, dirs_exist_ok=True)\n",
    "        except NotADirectoryError:\n",
    "            shutil.copy(self.src, self.dest)\n",
    "\n",
    "    def createExecutableBatchFile(self) -> str:\n",
    "        return \"{Result of the AbstractJob: createExecutableBatchFile}\"\n",
    "\n",
    "\n",
    "class MaxQuantJob(AbstractJob):\n",
    "    def __init__(\n",
    "        self,\n",
    "        BenchmarkingCSVFile_path,\n",
    "        InputFiles_path,\n",
    "        storage_path,\n",
    "        Number_of_jobs_repetition,\n",
    "\n",
    "    ):\n",
    "        super().__init__(\n",
    "            BenchmarkingCSVFile_path,\n",
    "            InputFiles_path,\n",
    "            storage_path,\n",
    "            Number_of_jobs_repetition,\n",
    "        )\n",
    "        # TODO: Variables needs to be initialize \n",
    "        # self.sample_files = sample_files\n",
    "        # self.xml_file_path = xml_file_path\n",
    "        # self.numthreads = numthreads\n",
    "\n",
    "    def createExecutableBatchFile(self, job_parameters, path, ExecutionID) -> None:\n",
    "        with open(f\"{path}{job_parameters['job-name']}_batch.sh\", \"w+\") as fb:\n",
    "            fb.writelines(\"#!/bin/bash\\n\")\n",
    "            fb.writelines(f\"#SBATCH -p {job_parameters['partition']}\\n\")\n",
    "            fb.writelines(f\"#SBATCH --qos=regular_partitiontimelimit\\n\")\n",
    "            fb.writelines(f\"#SBATCH --job-name={job_parameters['job-name']}\\n\")\n",
    "            fb.writelines(f\"#SBATCH --ntasks=1\\n\")\n",
    "            fb.writelines(f\"#SBATCH --time={job_parameters['timelimit']}\\n\")\n",
    "            fb.writelines(\n",
    "                f\"#SBATCH --cpus-per-task={job_parameters['cpus-per-task']}\\n\"\n",
    "            )\n",
    "            fb.writelines(f\"#SBATCH --mem={job_parameters['mem']}G\\n\")\n",
    "            fb.writelines(f\"#SBATCH --output={path}slurm-%j.out\\n\")\n",
    "            fb.writelines(f\"#SBATCH --mail-type=ALL,ARRAY_TASKS\\n\")\n",
    "            fb.writelines(f\"#SBATCH --mail-user=romano.h@wehi.edu.au\\n\")\n",
    "\n",
    "            fb.writelines(f\"module load MaxQuant/2.0.2.0\\n\")\n",
    "            fb.writelines(f\"module load python/3.8.8\\n\")\n",
    "\n",
    "            fb.writelines(\n",
    "                f\"MaxQuant {path}mqpar.xml --changeFolder {path}mqpar.post.xml {path} {path}\\n\"\n",
    "            )\n",
    "\n",
    "            fb.writelines(f\"MaxQuant {path}mqpar.post.xml\\n\")\n",
    "\n",
    "            fb.writelines(\n",
    "                f\"find {path} -maxdepth 1 -mindepth 1 -type f -not -regex '.*\\.\\(fasta\\|xml\\|out\\|raw\\|sh\\)' -delete\\n\"\n",
    "            )\n",
    "            fb.writelines(\n",
    "                f\"find {path} -maxdepth 1 -mindepth 1 -type d -not -regex '.*\\.\\(d\\)' -exec rm -rf '{{}}' \\;\\n\"\n",
    "            )\n",
    "\n",
    "            fb.writelines(\n",
    "                f'echo \"\"$SLURM_ARRAY_JOB_ID\",\"$SLURM_ARRAY_TASK_ID\"\",{job_parameters[\"partition\"]},{job_parameters[\"type\"]},{job_parameters[\"job-name\"]},{job_parameters[\"NumFiles\"]},{job_parameters[\"cpus-per-task\"]},{job_parameters[\"mem\"]},{job_parameters[\"threads\"]},{job_parameters[\"timelimit\"]} >> jobs_executed_{ExecutionID}.txt\\n'\n",
    "            )\n",
    "\n",
    "        os.system(f\"sbatch {path}{job_parameters['job-name']}_batch.sh\")\n",
    "\n",
    "    def updateXmlFile(self, sample_files, xml_file_path, numthreads) -> None:\n",
    "        tree = ET.parse(xml_file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for filepath_tag in root.findall(\"filePaths/string\"):\n",
    "            root.findall(\"filePaths\")[0].remove(filepath_tag)\n",
    "\n",
    "        for sample_file in sample_files:\n",
    "            new_path = ET.Element(\"string\")\n",
    "            new_path.text = sample_file\n",
    "            root.findall(\"filePaths\")[0].append(new_path)\n",
    "\n",
    "        # <useDotNetCore>True</useDotNetCore>\n",
    "        root.findall(\"useDotNetCore\")[0].text = \"True\"\n",
    "        # <numThreads>8</numThreads>\n",
    "        root.findall(\"numThreads\")[0].text = str(numthreads)\n",
    "\n",
    "        outputfile = xml_file_path\n",
    "        tree.write(outputfile)\n",
    "\n",
    "\n",
    "class DiaNNJob(AbstractJob):\n",
    "    def __init__(\n",
    "        self,\n",
    "        BenchmarkingCSVFile_path,\n",
    "        InputFiles_path,\n",
    "        storage_path,\n",
    "        Number_of_jobs_repetition,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            BenchmarkingCSVFile_path,\n",
    "            InputFiles_path,\n",
    "            storage_path,\n",
    "            Number_of_jobs_repetition,\n",
    "        )\n",
    "\n",
    "    def createExecutableBatchFile(\n",
    "        self, job_parameters, path, sample_files, fasta_file, library_file, ExecutionID\n",
    "    ) -> None:\n",
    "        with open(f\"{path}{job_parameters['job-name']}_batch.sh\", \"w+\") as fb:\n",
    "            fb.writelines(\"#!/bin/bash\\n\")\n",
    "            fb.writelines(f\"#SBATCH -p {job_parameters['partition']}\\n\")\n",
    "            fb.writelines(f\"#SBATCH --qos=regular_partitiontimelimit\\n\")\n",
    "            fb.writelines(f\"#SBATCH --job-name={job_parameters['job-name']}\\n\")\n",
    "            fb.writelines(f\"#SBATCH --ntasks=1\\n\")\n",
    "            fb.writelines(f\"#SBATCH --time={job_parameters['timelimit']}\\n\")\n",
    "            fb.writelines(\n",
    "                f\"#SBATCH --cpus-per-task={job_parameters['cpus-per-task']}\\n\"\n",
    "            )\n",
    "            fb.writelines(f\"#SBATCH --mem={job_parameters['mem']}G\\n\")\n",
    "            fb.writelines(f\"#SBATCH --output={path}slurm-%j.out\\n\")\n",
    "            fb.writelines(f\"#SBATCH --mail-type=ALL\\n\")\n",
    "            fb.writelines(f\"#SBATCH --mail-user=romano.h@wehi.edu.au\\n\")\n",
    "\n",
    "            fb.writelines(f\"module use /stornext/System/data/modulefiles/sysbio\\n\")\n",
    "            fb.writelines(f\"module load DiaNN/1.8\\n\")\n",
    "\n",
    "            fb.writelines(f\"mkdir {path}output\\n\")\n",
    "\n",
    "            fb.writelines(f\"diann-1.8 \\\\\\n\")\n",
    "\n",
    "            for sample_file_path in sample_files:\n",
    "                name_of_folder = sample_file_path.split(\"/\")[-1]\n",
    "                fb.writelines(f\"--f {path}{name_of_folder} \\\\\\n\")\n",
    "\n",
    "            if job_parameters[\"type\"] == \"lib\":\n",
    "                fb.writelines(f'--lib \"{library_file}\" \\\\\\n')\n",
    "            else:\n",
    "                fb.writelines(f'--lib \"\" \\\\\\n')\n",
    "\n",
    "            fb.writelines(f\"--threads 44 --verbose 1 \\\\\\n\")\n",
    "            fb.writelines(f\"--out {path}output/outputreport.tsv \\\\\\n\")\n",
    "            fb.writelines(f\"--qvalue 0.01 --matrices \\\\\\n\")\n",
    "            fb.writelines(f\"--out-lib {path}output/spectrallib.tsv \\\\\\n\")\n",
    "\n",
    "            fb.writelines(f\"--gen-spec-lib --predictor --fasta {fasta_file} \\\\\\n\")\n",
    "            if job_parameters[\"type\"] == \"libfree\":\n",
    "                fb.writelines(f\"--fasta-search  --min-fr-mz 200 --max-fr-mz 1800 \\\\\\n\")\n",
    "                fb.writelines(\n",
    "                    f\"--missed-cleavages 1 --min-pep-len 7 --max-pep-len 30 --min-pr-mz 300 \\\\\\n\"\n",
    "                )\n",
    "                fb.writelines(\n",
    "                    f\"--max-pr-mz 1800 --min-pr-charge 1 --max-pr-charge 4 \\\\\\n\"\n",
    "                )\n",
    "\n",
    "            fb.writelines(f\"--met-excision --cut K*,R* \\\\\\n\")\n",
    "            fb.writelines(f\"--mass-acc 10 --mass-acc-ms1 10.0 \\\\\\n\")\n",
    "            fb.writelines(f\"--use-quant \\\\\\n\")\n",
    "            fb.writelines(\n",
    "                f\"--reanalyse --smart-profiling --peak-center --no-ifs-removal\\n\"\n",
    "            )\n",
    "\n",
    "            fb.writelines(\n",
    "                f\"find {path} -maxdepth 1 -mindepth 1 -type f -not -regex '.*\\.\\(fasta\\|tsv\\|sh\\|out\\)' -delete\\n\"\n",
    "            )\n",
    "\n",
    "            fb.writelines(\n",
    "                f\"find {path} -maxdepth 1 -mindepth 1 -type d -not -regex '.*\\.\\(d\\)' -exec rm -rf '{{}}' \\;\\n\"\n",
    "            )\n",
    "\n",
    "            fb.writelines(\n",
    "                f'echo \"\"$SLURM_JOB_ID\"\",{job_parameters[\"partition\"]},{job_parameters[\"type\"]},{job_parameters[\"job-name\"]},{job_parameters[\"NumFiles\"]},{job_parameters[\"cpus-per-task\"]},{job_parameters[\"mem\"]},{job_parameters[\"threads\"]},{job_parameters[\"timelimit\"]} >> jobs_executed_{ExecutionID}.txt\\n'\n",
    "            )\n",
    "\n",
    "        os.system(f\"sbatch {path}{job_parameters['job-name']}_batch.sh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BenchmarkingToolCreator(ABC):\n",
    "    \"\"\"\n",
    "    The BenchmarkingToolCreator class declares the factory method that is supposed to return an\n",
    "    object of a Job class. The BenchmarkingToolCreator's subclasses usually provide the\n",
    "    implementation of this method.\n",
    "    \"\"\"\n",
    "    def __init__(self, BenchmarkingCSVFile_path, InputFiles_path, storage_path, Number_of_jobs_repetition):\n",
    "        self.BenchmarkingCSVFile_path = BenchmarkingCSVFile_path\n",
    "        self.InputFiles_path = InputFiles_path\n",
    "        self.storage_path = storage_path\n",
    "        self.Number_of_jobs_repetition = Number_of_jobs_repetition\n",
    "\n",
    "    @abstractmethod\n",
    "    def factory_method_create_job(self):\n",
    "        \"\"\"\n",
    "        Note that the BenchmarkingToolCreator may also provide some default implementation of\n",
    "        the factory method.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def runBenchmarking(self) -> str:\n",
    "        \"\"\"\n",
    "        Also note that, despite its name, the BenchmarkingToolCreator's primary responsibility\n",
    "        is not creating jobs. Usually, it contains some core business logic\n",
    "        that relies on Job objects, returned by the factory method.\n",
    "        Subclasses can indirectly change that business logic by overriding the\n",
    "        factory method and returning a different type of job from it.\n",
    "        \"\"\"\n",
    "\n",
    "        # Call the factory method to create a Job object.\n",
    "        job = self.factory_method_create_job()\n",
    "\n",
    "        # Now, use the job.\n",
    "        result = f\"BenchmarkingToolCreator: The same creator's code has just worked with {job.readBenchmarkingProfiles()}\"\n",
    "\n",
    "        # TODO: Inside of this method will be our core business logic\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Concrete Creators override the factory method in order to change the resulting\n",
    "product's type.\n",
    "\"\"\"\n",
    "\n",
    "class MQBenchmarkingTool(BenchmarkingToolCreator):\n",
    "    \"\"\"\n",
    "    Note that the signature of the method still uses the abstract job type,\n",
    "    even though the concrete job is actually returned from the method. This\n",
    "    way the BenchmarkingToolCreator can stay independent of concrete job classes.\n",
    "    \"\"\"\n",
    "    def __init__(self,BenchmarkingCSVFile_path, InputFiles_path, storage_path, Number_of_jobs_repetition,):\n",
    "        super().__init__(BenchmarkingCSVFile_path, InputFiles_path, storage_path, Number_of_jobs_repetition)\n",
    "\n",
    "        # TODO: Variables needs to be initialize\n",
    "        # Extract the list of Input filenames: .Fasta, .XML and .d\n",
    "        # original_files = glob.glob(InputFiles_path + \"*.d\", recursive=False)\n",
    "\n",
    "        # Create a Dictionary to store Input Files Orderly\n",
    "        # MaxQuantInputFiles = {}\n",
    "        # MaxQuantInputFiles[\"fasta_file\"] = glob.glob(InputFiles_path + \"*.fasta\", recursive=False)[0]\n",
    "        # MaxQuantInputFiles[\"xml_file\"] = glob.glob(InputFiles_path + \"*.xml\", recursive=False)[0]\n",
    "\n",
    "        # self.sample_files = sample_files\n",
    "        # self.xml_file_path = xml_file_path\n",
    "        # self.numthreads = numthreads\n",
    "        \n",
    "    def factory_method_create_job(self) -> Job:\n",
    "        return MaxQuantJob(self.BenchmarkingCSVFile_path,self.InputFiles_path,self.storage_path,self.Number_of_jobs_repetition )\n",
    "\n",
    "\n",
    "class DiaNNBenchmarkingTool(BenchmarkingToolCreator):\n",
    "    def __init__(self,BenchmarkingCSVFile_path, InputFiles_path, storage_path, Number_of_jobs_repetition):\n",
    "        super().__init__(BenchmarkingCSVFile_path, InputFiles_path, storage_path, Number_of_jobs_repetition)\n",
    "        \n",
    "    def factory_method_create_job(self) -> Job:\n",
    "        return DiaNNJob(self.BenchmarkingCSVFile_path,self.InputFiles_path,self.storage_path,self.Number_of_jobs_repetition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add this function to your diagram\n",
    "def client_code(creator: BenchmarkingToolCreator) -> None:\n",
    "    \"\"\"\n",
    "    The client code works with an instance of a concrete creator, albeit through\n",
    "    its base interface. As long as the client keeps working with the creator via\n",
    "    the base interface, you can pass it any creator's subclass.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\n",
    "        f\"Client: I'm not aware of the creator's class, but it still works.\\n\"\n",
    "        f\"{creator.runBenchmarking()}\",\n",
    "        end=\"\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App: Launched with the DiaNNBenchmarkingTool.\n",
      "Client: I'm not aware of the creator's class, but it still works.\n",
      "BenchmarkingToolCreator: The same creator's code has just worked with [{'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-1', 'NumFiles': '2', 'cpus-per-task': '10', 'mem': '40', 'threads': '2', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-2', 'NumFiles': '2', 'cpus-per-task': '12', 'mem': '80', 'threads': '8', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-3', 'NumFiles': '2', 'cpus-per-task': '14', 'mem': '120', 'threads': '16', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-4', 'NumFiles': '2', 'cpus-per-task': '16', 'mem': '160', 'threads': '32', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-5', 'NumFiles': '2', 'cpus-per-task': '18', 'mem': '200', 'threads': '64', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-6', 'NumFiles': '10', 'cpus-per-task': '10', 'mem': '40', 'threads': '2', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-7', 'NumFiles': '10', 'cpus-per-task': '12', 'mem': '80', 'threads': '8', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-8', 'NumFiles': '10', 'cpus-per-task': '14', 'mem': '120', 'threads': '16', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-9', 'NumFiles': '10', 'cpus-per-task': '16', 'mem': '160', 'threads': '32', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-10', 'NumFiles': '10', 'cpus-per-task': '18', 'mem': '200', 'threads': '64', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-11', 'NumFiles': '21', 'cpus-per-task': '10', 'mem': '40', 'threads': '2', 'timelimit': '48:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-12', 'NumFiles': '21', 'cpus-per-task': '12', 'mem': '80', 'threads': '8', 'timelimit': '48:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-13', 'NumFiles': '21', 'cpus-per-task': '14', 'mem': '120', 'threads': '16', 'timelimit': '48:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-14', 'NumFiles': '21', 'cpus-per-task': '16', 'mem': '160', 'threads': '32', 'timelimit': '48:00:00'}, {'partition': 'regular', 'type': 'lib', 'job-name': 'DiaNN-15', 'NumFiles': '21', 'cpus-per-task': '18', 'mem': '200', 'threads': '64', 'timelimit': '48:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-16', 'NumFiles': '2', 'cpus-per-task': '10', 'mem': '40', 'threads': '2', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-17', 'NumFiles': '2', 'cpus-per-task': '12', 'mem': '80', 'threads': '8', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-18', 'NumFiles': '2', 'cpus-per-task': '14', 'mem': '120', 'threads': '16', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-19', 'NumFiles': '2', 'cpus-per-task': '16', 'mem': '160', 'threads': '32', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-20', 'NumFiles': '2', 'cpus-per-task': '18', 'mem': '200', 'threads': '64', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-21', 'NumFiles': '10', 'cpus-per-task': '10', 'mem': '40', 'threads': '2', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-22', 'NumFiles': '10', 'cpus-per-task': '12', 'mem': '80', 'threads': '8', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-23', 'NumFiles': '10', 'cpus-per-task': '14', 'mem': '120', 'threads': '16', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-24', 'NumFiles': '10', 'cpus-per-task': '16', 'mem': '160', 'threads': '32', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-25', 'NumFiles': '10', 'cpus-per-task': '18', 'mem': '200', 'threads': '64', 'timelimit': '24:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-26', 'NumFiles': '21', 'cpus-per-task': '10', 'mem': '40', 'threads': '2', 'timelimit': '48:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-27', 'NumFiles': '21', 'cpus-per-task': '12', 'mem': '80', 'threads': '8', 'timelimit': '48:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-28', 'NumFiles': '21', 'cpus-per-task': '14', 'mem': '120', 'threads': '16', 'timelimit': '48:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-29', 'NumFiles': '21', 'cpus-per-task': '16', 'mem': '160', 'threads': '32', 'timelimit': '48:00:00'}, {'partition': 'regular', 'type': 'libfree', 'job-name': 'DiaNN-30', 'NumFiles': '21', 'cpus-per-task': '18', 'mem': '200', 'threads': '64', 'timelimit': '48:00:00'}]"
     ]
    }
   ],
   "source": [
    "# Welcoming message\n",
    "BenchTool = input(\"Thanks for using BenchMe! Please select '1' if you want benchmark MQ or '2' for DiaNN\")\n",
    "\n",
    "InputFiles_path = input(\"Absolute path of Input DiaNN input files (.d, .fasta, .tsv). I.E: '/stornext/HPCScratch/home/romano.h/Software-Projects/Local-Repositories/DiaNN/DiaNNFiles-Dataset/'\")\n",
    "BenchmarkingCSVFile_path = input(\"Name of CSV file with DiaNN Profiles for benchmarking. I.E: 'benchmarking-profiles.csv'\")\n",
    "storage_path = input(\"Absolute path of storage directory to save outputs. I.E: '/vast/scratch/users/romano.h/DiaNNBenchmarking/'\")\n",
    "Number_of_jobs_repetition = input(\"Number of times to run each benchmarking profile job. Default: 5 times\")\n",
    "\n",
    "if BenchTool == '1':\n",
    "    print(\"App: Launched with the MQBenchmarkingTool.\")\n",
    "    client_code(MQBenchmarkingTool(InputFiles_path, BenchmarkingCSVFile_path, storage_path, Number_of_jobs_repetition))\n",
    "elif BenchTool == '2':\n",
    "    print(\"App: Launched with the DiaNNBenchmarkingTool.\")\n",
    "    client_code(DiaNNBenchmarkingTool(InputFiles_path, BenchmarkingCSVFile_path, storage_path, Number_of_jobs_repetition))\n",
    "else:\n",
    "    print(\"I am sorry, the selected option is invalid.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string(\"files\", None, \"Absolute path of Input DiaNN input files (.d, .fasta, .tsv). I.E: '/stornext/HPCScratch/home/romano.h/Software-Projects/Local-Repositories/DiaNN/DiaNNFiles-Dataset/'\")\n",
    "flags.DEFINE_string(\"profiles\", None, \"Name of CSV file with DiaNN Profiles for benchmarking. I.E: 'benchmarking-profiles.csv'\")\n",
    "flags.DEFINE_string(\"storage\", None, \"Absolute path of storage directory to save outputs. I.E: '/vast/scratch/users/romano.h/DiaNNBenchmarking/'\")\n",
    "flags.DEFINE_integer(\"repeat\", 5,\"Number of times to run each benchmarking profile job. Default: 5 times\")\n",
    "\n",
    "# Required flag.\n",
    "flags.mark_flag_as_required(\"files\")\n",
    "flags.mark_flag_as_required(\"profiles\")\n",
    "flags.mark_flag_as_required(\"storage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"App: Launched with the MQBenchmarkingTool.\")\n",
    "    client_code(MQBenchmarkingTool())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"App: Launched with the DiaNNBenchmarkingTool.\")\n",
    "    client_code(DiaNNBenchmarkingTool())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1cd49daa982e2d0df3520171ed1bc31370236c716747a62405fce76878819793"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('testexample-xrcCy3tl': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
